 #La historia de hadoop

_Comienzos_

### Pre-requisitos 
_EstasInspir谩ndose en la computaci贸n en paralelo de Google, los programadores Mike Cafarella y Doug Cutting lanzaron la primera versi贸n de Hadoop el 1 de abril de 2006. Se trata de una soluci贸n de c贸digo abierto que emplea la computaci贸n en paralelo para procesar y analizar vol煤menes enormes de data. 
Cutting inici贸 la investigaci贸n mientras trabajaba en Google, y la continu贸 al marcharse a Yahoo. Entonces se enmarc贸 en el proyecto de desarrollo de Nutch, motor de b煤squeda de esta 煤ltima compa帽铆a, este proyecto ten铆a problemas de escalabilidad, ley贸 el paper de Google y lo implemento, dando lugar a Hadoop y HDFS como proyectos de Apache. El proyecto de Nutch se dividi贸: la parte del rastreador web permaneci贸 como Nutch y la porci贸n de procesamiento y computaci贸n distribuida se convirti贸 en Hadoop (que lleva el nombre del elefante de juguete del hijo de Cutting). Poco despu茅s creo Cloudera._


## Desarrollo 

_Hadoop se desarroll贸 como un modelo de procesamiento autom谩tico basado en computaci贸n en paralelo extrapolable a cualquier programa de procesamiento de grandes vol煤menes de datos.
Hadoop es un framework de c贸digo abierto, esto es, que cualquier persona puede acceder a sus componentes de forma libre y gratuita, y los puede modificar y adaptar a las necesidades particulares del proyecto que est茅 desarrollando. Esto, unido a su eficacia, hace que, a d铆a de hoy, siga siendo el sistema m谩s empleado en Big Data.
El bajo costo del hardware b谩sico hace que Hadoop sea muy 煤til para almacenar y combinar datos como transaccionales, redes sociales, sensores, m谩quinas, cient铆ficos, transmisiones de clics, etc. El almacenamiento de bajo costo le permite mantener informaci贸n que no se considera actualmente cr铆tica, pero con la posibilidad de que usted la analice despu茅s._


